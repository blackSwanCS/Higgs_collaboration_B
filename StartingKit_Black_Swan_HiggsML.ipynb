{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Starting Kit - Black Swan HiggsML Course\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = \"google.colab\" in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    ! git clone --depth 1 https://github.com/blackSwanCS/Higgs_collaboration_B.git\n",
    "    ! git status\n",
    "    %cd /Higgs_collaboration_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiggsML utility package should not be modified\n",
    "%pip install HiggsML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from numpy.random import RandomState\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory is c:\\Users\\marti\\Documents\\1A CS\\Higgs\\Higgs_collaboration_B\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.getcwd()\n",
    "print(\"Root directory is\", root_dir)\n",
    "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
    "\n",
    "# The directory where results and other outputs from the participant's code will be written\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Submission Model\n",
    "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
    "- `init`: receives train set and systematics class as input\n",
    "- `fit`: can be used for training\n",
    "- `predict`: receives one test set and outputs a dictionary with the following keys\n",
    "    - `mu_hat` : predicted mu $\\hat{\\mu}$\n",
    "    - `delta_mu_hat`: $\\Delta{\\hat{\\mu}}$ bound for $\\mu$\n",
    "    - `p16`: 16th percentile\n",
    "    - `p84`: 84th percentile\n",
    "\n",
    "In this example code, the `Model` class implements a basic model with 2 different model trained to predict the class label. \n",
    "\n",
    "* 1 XGBoost BDT ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/boosted_decision_tree.py) )\n",
    "* 2 Tebsorflow NN  ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/neural_network.py) )\n",
    "\n",
    "The feature engineering is in where you can include derived quantities and decide which feature should be needed. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/feature_engineering.py) ) \n",
    "\n",
    "the statistical analysis part is where yoiu write the mu finding calculation using the output of the classifier. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/statistical_analysis.py) ) \n",
    "\n",
    "If running in Collab, click the folder icon in the left sidebar to open the file browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(submission_dir)\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Available data sets\n",
    "1. blackSwan_data\n",
    "2. sample_data\n",
    "3. neurips2024_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 16:08:27,024 - HiggsML.datasets     - INFO     - Handling as dataset name: blackSwan_data\n",
      "2025-06-03 16:08:27,026 - HiggsML.datasets     - INFO     - Current working directory: c:\\Users\\marti\\Documents\\1A CS\\Higgs\\Higgs_collaboration_B\n",
      "2025-06-03 16:08:27,033 - HiggsML.datasets     - INFO     - Total rows: 2000000\n",
      "2025-06-03 16:08:27,034 - HiggsML.datasets     - INFO     - Test size: 600000\n"
     ]
    }
   ],
   "source": [
    "from HiggsML.datasets import download_dataset\n",
    "\n",
    "data = download_dataset(\n",
    "    \"blackSwan_data\"\n",
    ")  # change to \"blackSwan_data\" for the actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Note:\n",
    "The data used here is a small subset of the full data is for demonstration only to get a view of what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 16:08:30,371 - HiggsML.datasets     - INFO     - Selected train size: 1400000\n",
      "2025-06-03 16:08:31,862 - HiggsML.datasets     - INFO     - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# load train set\n",
    "data.load_train_set()\n",
    "data_set = data.get_train_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Visualize the Data Set\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "target = data_set[\"labels\"]\n",
    "weights = data_set[\"weights\"]\n",
    "detailed_label = data_set[\"detailed_labels\"]\n",
    "keys = np.unique(detailed_label)\n",
    "\n",
    "\n",
    "weight_keys = {}\n",
    "average_weights = {}\n",
    "for key in keys:\n",
    "    weight_keys[key] = weights[detailed_label == key]\n",
    "\n",
    "table_data = []\n",
    "for key in keys:\n",
    "    table_data.append(\n",
    "        [\n",
    "            key,\n",
    "            np.sum(weight_keys[key]),\n",
    "            len(weight_keys[key]),\n",
    "            np.mean(weight_keys[key]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "table_data.append(\n",
    "    [\n",
    "        \"Total Signal\",\n",
    "        np.sum(weights[target == 1]),\n",
    "        len(weights[target == 1]),\n",
    "        np.mean(weights[target == 1]),\n",
    "    ]\n",
    ")\n",
    "table_data.append(\n",
    "    [\n",
    "        \"Total Background\",\n",
    "        np.sum(weights[target == 0]),\n",
    "        len(weights[target == 0]),\n",
    "        np.mean(weights[target == 0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"[*] --- Detailed Label Summary\")\n",
    "print(\n",
    "    tabulate(\n",
    "        table_data,\n",
    "        headers=[\n",
    "            \"Detailed Label\",\n",
    "            \"Total Weight\",\n",
    "            \"Number of events\",\n",
    "            \"Average Weight\",\n",
    "        ],\n",
    "        tablefmt=\"grid\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[*] --- Examples of all features\\n\")\n",
    "display(data_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[*] --- Description of all features\\n\")\n",
    "display(data_set.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import histogram_dataset\n",
    "\n",
    "# this function is defined in utils.py in the sample_code_submission directory. feel free to modify it as needed\n",
    "\n",
    "histogram_dataset(\n",
    "    data_set,\n",
    "    target,\n",
    "    weights,\n",
    "    columns=[\"PRI_lep_phi\", \"PRI_met\", \"DER_mass_vis\", \"DER_deltaeta_jet_jet\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(rc={\"figure.figsize\": (10, 10)}, style=\"whitegrid\")\n",
    "\n",
    "caption = [\"Signal feature\", \"Background feature\"]\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    dfplot = pd.DataFrame(\n",
    "        data_set,\n",
    "        columns=[\n",
    "            \"PRI_lep_phi\",\n",
    "            \"PRI_met\",\n",
    "            \"DER_pt_ratio_lep_had\",\n",
    "            \"DER_deltaeta_jet_jet\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(caption[i], \" correlation matrix\")\n",
    "    corrMatrix = dfplot[target == i].corr()\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.title(\"Correlation matrix of features\")\n",
    "    plt.show()\n",
    "\n",
    "del dfplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import stacked_histogram\n",
    "\n",
    "stacked_histogram(data_set, target, weights, detailed_label, \"PRI_jet_subleading_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import pair_plots\n",
    "\n",
    "# Show data summary\n",
    "pair_plots(\n",
    "    data_set,\n",
    "    target,\n",
    "    sample_size=100,\n",
    "    columns=[\n",
    "        \"PRI_lep_phi\",\n",
    "        \"PRI_met\",\n",
    "        \"DER_lep_eta_centrality\",\n",
    "        \"DER_deltaeta_jet_jet\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Settings\n",
    "The Test setting sets the test conditions in ingestion.\n",
    "This includes what systematics you want and how many psuedo experiments you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETTINGS = {\n",
    "    \"systematics\": {  # Systematics to use\n",
    "        \"tes\": False,  # tau energy scale\n",
    "        \"jes\": False,  # jet energy scale\n",
    "        \"soft_met\": False,  # soft term in MET\n",
    "        \"ttbar_scale\": False,  # W boson scale factor\n",
    "        \"diboson_scale\": False,  # Diboson scale factor\n",
    "        \"bkg_scale\": False,  # Background scale factor\n",
    "    },\n",
    "    \"num_pseudo_experiments\": 25,  # Number of pseudo-experiments to run per set\n",
    "    \"num_of_sets\": 25,  # Number of sets of pseudo-experiments to run\n",
    "}\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "random_state = np.random.RandomState(RANDOM_SEED)\n",
    "test_settings[\"ground_truth_mus\"] = (\n",
    "    random_state.uniform(0.1, 3, test_settings[\"num_of_sets\"])\n",
    ").tolist()\n",
    "\n",
    "random_settings_file = os.path.join(output_dir, \"test_settings.json\")\n",
    "with open(random_settings_file, \"w\") as f:\n",
    "    json.dump(test_settings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.ingestion import Ingestion\n",
    "\n",
    "ingestion = Ingestion(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 16:08:41,424 - HiggsML.ingestion    - INFO     - Initializing Submmited Model\n",
      "2025-06-03 16:08:41,430 - HiggsML.datasets     - INFO     - Selected train size: 5000\n",
      "2025-06-03 16:08:42,058 - HiggsML.datasets     - INFO     - Data loaded successfully\n",
      "2025-06-03 16:08:42,082 - HiggsML.datasets     - INFO     - Selected train size: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:  (5000, 28)\n",
      "Training Labels:  (5000,)\n",
      "Training Weights:  (5000,)\n",
      "sum_signal_weights:  676.7364256454059\n",
      "sum_bkg_weights:  105042.26357435457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 16:08:42,637 - HiggsML.datasets     - INFO     - Data loaded successfully\n",
      "2025-06-03 16:08:42,661 - HiggsML.datasets     - INFO     - Selected train size: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid Data:  (5000, 28)\n",
      "Valid Labels:  (5000,)\n",
      "Valid Weights:  (5000,)\n",
      "sum_signal_weights:  670.7835309817206\n",
      "sum_bkg_weights:  105048.21646901831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 16:08:43,171 - HiggsML.datasets     - INFO     - Data loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Holdout Data:  (5000, 28)\n",
      "Holdout Labels:  (5000,)\n",
      "Holdout Weights:  (5000,)\n",
      "sum_signal_weights:  653.9504661931351\n",
      "sum_bkg_weights:  105065.04953380686\n",
      " \n",
      " \n",
      "Training Data:  (5000, 28)\n",
      "DEBUG: model_type = 'NN'\n",
      " Model is NN\n"
     ]
    }
   ],
   "source": [
    "# initialize submission\n",
    "ingestion.init_submission(Model,\"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 16:08:51,728 - HiggsML.ingestion    - INFO     - Calling fit method of submitted model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157/157 - 3s - 17ms/step - accuracy: 0.5220 - loss: 30.1668\n",
      "Epoch 2/5\n",
      "157/157 - 1s - 3ms/step - accuracy: 0.7204 - loss: 25.3935\n",
      "Epoch 3/5\n",
      "157/157 - 1s - 3ms/step - accuracy: 0.7390 - loss: 23.9160\n",
      "Epoch 4/5\n",
      "157/157 - 1s - 3ms/step - accuracy: 0.7486 - loss: 22.9422\n",
      "Epoch 5/5\n",
      "157/157 - 1s - 4ms/step - accuracy: 0.7588 - loss: 22.3342\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# fit submission\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mingestion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\HiggsML\\ingestion.py:141\u001b[39m, in \u001b[36mIngestion.fit_submission\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03mFit the submitted model.\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    140\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mCalling fit method of submitted model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marti\\Documents\\1A CS\\Higgs\\Higgs_collaboration_B\\sample_code_submission\\model.py:240\u001b[39m, in \u001b[36mModel.fit\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# test dataset : increase test weight to compensate for sampling\u001b[39;00m\n\u001b[32m    238\u001b[39m balanced_set[\u001b[33m\"\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m\"\u001b[39m] = weights_train\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbalanced_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbalanced_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbalanced_set\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweights\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[38;5;28mself\u001b[39m.holdout_set = \u001b[38;5;28mself\u001b[39m.systematics(\u001b[38;5;28mself\u001b[39m.holdout_set)\n\u001b[32m    246\u001b[39m \u001b[38;5;28mself\u001b[39m.saved_info = calculate_saved_info(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.holdout_set)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\marti\\Documents\\1A CS\\Higgs\\Higgs_collaboration_B\\sample_code_submission\\neural_network.py:55\u001b[39m, in \u001b[36mNeuralNetwork.fit\u001b[39m\u001b[34m(self, train_data, y_train, weights_train)\u001b[39m\n\u001b[32m     51\u001b[39m X_train = \u001b[38;5;28mself\u001b[39m.scaler.transform(train_data)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mself\u001b[39m.model.fit(\n\u001b[32m     53\u001b[39m     X_train, y_train, sample_weight=weights_train, epochs=\u001b[32m5\u001b[39m, verbose=\u001b[32m2\u001b[39m\n\u001b[32m     54\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "# fit submission\n",
    "ingestion.fit_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "data.load_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict submission\n",
    "ingestion.predict_submission(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestion.process_results_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "ingestion.save_result(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "1. Compute Scores\n",
    "2. Visualize Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.score import Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Score\n",
    "score = Scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir)\n",
    "score.load_ingestion_results(prediction_dir=output_dir, score_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Score\n",
    "score.compute_scores(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import visualize_scatter\n",
    "\n",
    "# Visualize scatter plot of ground truth mu and predicted mu\n",
    "visualize_scatter(\n",
    "    ingestion_result_dict=ingestion.results_dict,\n",
    "    ground_truth_mus=test_settings[\"ground_truth_mus\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m HiggsML.score --prediction $output_dir --output $output_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
