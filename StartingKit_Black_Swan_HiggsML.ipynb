{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Starting Kit - Black Swan HiggsML Course\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = \"google.colab\" in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    ! git clone --depth 1 https://github.com/blackSwanCS/Higgs_collaboration_B.git\n",
    "    ! git status\n",
    "    %cd /Higgs_collaboration_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiggsML utility package should not be modified\n",
    "%pip install HiggsML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from numpy.random import RandomState\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "print(\"Root directory is\", root_dir)\n",
    "submission_dir = os.path.join(root_dir, \"sample_code_submission\")\n",
    "\n",
    "# The directory where results and other outputs from the participant's code will be written\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Submission Model\n",
    "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
    "- `init`: receives train set and systematics class as input\n",
    "- `fit`: can be used for training\n",
    "- `predict`: receives one test set and outputs a dictionary with the following keys\n",
    "    - `mu_hat` : predicted mu $\\hat{\\mu}$\n",
    "    - `delta_mu_hat`: $\\Delta{\\hat{\\mu}}$ bound for $\\mu$\n",
    "    - `p16`: 16th percentile\n",
    "    - `p84`: 84th percentile\n",
    "\n",
    "In this example code, the `Model` class implements a basic model with 2 different model trained to predict the class label. \n",
    "\n",
    "* 1 XGBoost BDT ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/boosted_decision_tree.py) )\n",
    "* 2 Tebsorflow NN  ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/neural_network.py) )\n",
    "\n",
    "The feature engineering is in where you can include derived quantities and decide which feature should be needed. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/feature_engineering.py) ) \n",
    "\n",
    "the statistical analysis part is where yoiu write the mu finding calculation using the output of the classifier. ( [see](/home/chakkappai/Work/ST4_CS/Collaboration_A/sample_code_submission/statistical_analysis.py) ) \n",
    "\n",
    "If running in Collab, click the folder icon in the left sidebar to open the file browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.append(submission_dir)\n",
    "from sample_code_submission.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Available data sets\n",
    "1. blackSwan_data\n",
    "2. sample_data\n",
    "3. neurips2024_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.datasets import download_dataset\n",
    "\n",
    "data = download_dataset(\n",
    "    \"blackSwan_data\"\n",
    ")  # change to \"blackSwan_data\" for the actual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Note:\n",
    "The data used here is a small subset of the full data is for demonstration only to get a view of what the data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train set\n",
    "data.load_train_set()\n",
    "data_set = data.get_train_set()\n",
    "print(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Visualize the Data Set\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "target = data_set[\"labels\"]\n",
    "weights = data_set[\"weights\"]\n",
    "detailed_label = data_set[\"detailed_labels\"]\n",
    "keys = np.unique(detailed_label)\n",
    "\n",
    "\n",
    "weight_keys = {}\n",
    "average_weights = {}\n",
    "for key in keys:\n",
    "    weight_keys[key] = weights[detailed_label == key]\n",
    "\n",
    "table_data = []\n",
    "for key in keys:\n",
    "    table_data.append(\n",
    "        [\n",
    "            key,\n",
    "            np.sum(weight_keys[key]),\n",
    "            len(weight_keys[key]),\n",
    "            np.mean(weight_keys[key]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "table_data.append(\n",
    "    [\n",
    "        \"Total Signal\",\n",
    "        np.sum(weights[target == 1]),\n",
    "        len(weights[target == 1]),\n",
    "        np.mean(weights[target == 1]),\n",
    "    ]\n",
    ")\n",
    "table_data.append(\n",
    "    [\n",
    "        \"Total Background\",\n",
    "        np.sum(weights[target == 0]),\n",
    "        len(weights[target == 0]),\n",
    "        np.mean(weights[target == 0]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"[*] --- Detailed Label Summary\")\n",
    "print(\n",
    "    tabulate(\n",
    "        table_data,\n",
    "        headers=[\n",
    "            \"Detailed Label\",\n",
    "            \"Total Weight\",\n",
    "            \"Number of events\",\n",
    "            \"Average Weight\",\n",
    "        ],\n",
    "        tablefmt=\"grid\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[*] --- Examples of all features\\n\")\n",
    "display(data_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[*] --- Description of all features\\n\")\n",
    "display(data_set.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import histogram_dataset\n",
    "\n",
    "# this function is defined in utils.py in the sample_code_submission directory. feel free to modify it as needed\n",
    "\n",
    "histogram_dataset(\n",
    "    data_set,\n",
    "    target,\n",
    "    weights,\n",
    "    columns=[\"PRI_lep_phi\", \"PRI_met\", \"DER_mass_vis\", \"DER_deltaeta_jet_jet\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(rc={\"figure.figsize\": (10, 10)}, style=\"whitegrid\")\n",
    "\n",
    "caption = [\"Signal feature\", \"Background feature\"]\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    dfplot = pd.DataFrame(\n",
    "        data_set,\n",
    "        columns=[\n",
    "            \"PRI_lep_phi\",\n",
    "            \"PRI_met\",\n",
    "            \"DER_pt_ratio_lep_had\",\n",
    "            \"DER_deltaeta_jet_jet\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(caption[i], \" correlation matrix\")\n",
    "    corrMatrix = dfplot[target == i].corr()\n",
    "    sns.heatmap(corrMatrix, annot=True)\n",
    "    plt.title(\"Correlation matrix of features\")\n",
    "    plt.show()\n",
    "\n",
    "del dfplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import stacked_histogram\n",
    "\n",
    "stacked_histogram(data_set, target, weights, detailed_label, \"PRI_jet_subleading_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import pair_plots\n",
    "\n",
    "# Show data summary\n",
    "pair_plots(\n",
    "    data_set,\n",
    "    target,\n",
    "    sample_size=100,\n",
    "    columns=[\n",
    "        \"PRI_lep_phi\",\n",
    "        \"PRI_met\",\n",
    "        \"DER_lep_eta_centrality\",\n",
    "        \"DER_deltaeta_jet_jet\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Settings\n",
    "The Test setting sets the test conditions in ingestion.\n",
    "This includes what systematics you want and how many psuedo experiments you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETTINGS = {\n",
    "    \"systematics\": {  # Systematics to use\n",
    "        \"tes\": False,  # tau energy scale\n",
    "        \"jes\": False,  # jet energy scale\n",
    "        \"soft_met\": False,  # soft term in MET\n",
    "        \"ttbar_scale\": False,  # W boson scale factor\n",
    "        \"diboson_scale\": False,  # Diboson scale factor\n",
    "        \"bkg_scale\": False,  # Background scale factor\n",
    "    },\n",
    "    \"num_pseudo_experiments\": 25,  # Number of pseudo-experiments to run per set\n",
    "    \"num_of_sets\": 25,  # Number of sets of pseudo-experiments to run\n",
    "}\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "random_state = np.random.RandomState(RANDOM_SEED)\n",
    "test_settings[\"ground_truth_mus\"] = (\n",
    "    random_state.uniform(0.1, 3, test_settings[\"num_of_sets\"])\n",
    ").tolist()\n",
    "\n",
    "random_settings_file = os.path.join(output_dir, \"test_settings.json\")\n",
    "with open(random_settings_file, \"w\") as f:\n",
    "    json.dump(test_settings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.ingestion import Ingestion\n",
    "\n",
    "ingestion = Ingestion(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize submission\n",
    "ingestion.init_submission(Model, \"BDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit submission\n",
    "ingestion.fit_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "data.load_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict submission\n",
    "ingestion.predict_submission(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestion.process_results_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result\n",
    "ingestion.save_result(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "1. Compute Scores\n",
    "2. Visualize Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.score import Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Score\n",
    "score = Scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dir)\n",
    "score.load_ingestion_results(prediction_dir=output_dir, score_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Score\n",
    "score.compute_scores(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HiggsML.visualization import visualize_scatter\n",
    "\n",
    "# Visualize scatter plot of ground truth mu and predicted mu\n",
    "visualize_scatter(\n",
    "    ingestion_result_dict=ingestion.results_dict,\n",
    "    ground_truth_mus=test_settings[\"ground_truth_mus\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m HiggsML.score --prediction $output_dir --output $output_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
